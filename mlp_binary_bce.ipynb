{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ea99af-92d5-47ea-92d5-6a35bfadaa5c",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd40ed8-1f58-4c96-9af1-1152a3f8dbdd",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6488ef-9417-4e61-a688-648aa55c90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccd9c6f-1d5c-43f3-8d0b-3c5308dddf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, n_classes=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3a3faf-ba2c-4762-a9e2-503b6b4ac6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff5f039-966a-429f-8d2e-126e434c2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a48681-457c-41e7-80dc-a336493b4945",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f0438d-30d6-4c0a-ad9f-9dec5291788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else\\\n",
    "         \"mps\" if torch.backends.mps.is_available() else\\\n",
    "         \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01ac5be-b060-4ca5-b4f0-4cc33cf49781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=16, output_dim=1):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca33105-e94a-47bc-b3ce-4327dc791215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    lr         = 1e-3\n",
    "    batch_size = 32\n",
    "    num_epochs = 100\n",
    "    steps      = num_epochs // 10\n",
    "    k          = 5\n",
    "\n",
    "    X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "    y_torch = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "    dataset = TensorDataset(X_torch, y_torch)\n",
    "\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{k} ---\")\n",
    "        train_sub = Subset(dataset, train_index)\n",
    "        val_sub   = Subset(dataset, val_index)\n",
    "\n",
    "        train_loader = DataLoader(train_sub, batch_size=batch_size, shuffle=True)\n",
    "        val_loader   = DataLoader(val_sub, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "        model = MLP(input_dim=n_features)\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        # criterion = nn.BCEWithLogitsLoss()\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits  = model(x_batch)\n",
    "                loss    = criterion(logits, y_batch.float())\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "            if (epoch + 1) % steps == 0:\n",
    "                avg_loss = total_loss / len(train_loader)\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                logits = model(x_batch)\n",
    "                preds  = (logits >= 0.5).long()\n",
    "                correct += (preds == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        fold_accuracies.append(acc)\n",
    "        print(f\"Fold {fold+1} Accuracy: {acc:.2f}\")\n",
    "\n",
    "    print(f\"\\nAverage accuracy across {k} folds: {np.mean(fold_accuracies):.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a59416e-631e-4fc3-aeb5-954f61e7f6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 10/100, Loss: 0.4236\n",
      "Epoch 20/100, Loss: 0.2696\n",
      "Epoch 30/100, Loss: 0.2098\n",
      "Epoch 40/100, Loss: 0.1747\n",
      "Epoch 50/100, Loss: 0.1497\n",
      "Epoch 60/100, Loss: 0.1312\n",
      "Epoch 70/100, Loss: 0.1165\n",
      "Epoch 80/100, Loss: 0.1042\n",
      "Epoch 90/100, Loss: 0.0935\n",
      "Epoch 100/100, Loss: 0.0846\n",
      "Fold 1 Accuracy: 0.96\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 10/100, Loss: 0.4268\n",
      "Epoch 20/100, Loss: 0.2856\n",
      "Epoch 30/100, Loss: 0.2242\n",
      "Epoch 40/100, Loss: 0.1867\n",
      "Epoch 50/100, Loss: 0.1607\n",
      "Epoch 60/100, Loss: 0.1408\n",
      "Epoch 70/100, Loss: 0.1243\n",
      "Epoch 80/100, Loss: 0.1111\n",
      "Epoch 90/100, Loss: 0.1008\n",
      "Epoch 100/100, Loss: 0.0917\n",
      "Fold 2 Accuracy: 0.93\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 10/100, Loss: 0.4136\n",
      "Epoch 20/100, Loss: 0.2694\n",
      "Epoch 30/100, Loss: 0.2068\n",
      "Epoch 40/100, Loss: 0.1695\n",
      "Epoch 50/100, Loss: 0.1459\n",
      "Epoch 60/100, Loss: 0.1277\n",
      "Epoch 70/100, Loss: 0.1134\n",
      "Epoch 80/100, Loss: 0.1011\n",
      "Epoch 90/100, Loss: 0.0908\n",
      "Epoch 100/100, Loss: 0.0822\n",
      "Fold 3 Accuracy: 0.95\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 10/100, Loss: 0.4462\n",
      "Epoch 20/100, Loss: 0.2757\n",
      "Epoch 30/100, Loss: 0.2089\n",
      "Epoch 40/100, Loss: 0.1692\n",
      "Epoch 50/100, Loss: 0.1404\n",
      "Epoch 60/100, Loss: 0.1184\n",
      "Epoch 70/100, Loss: 0.1020\n",
      "Epoch 80/100, Loss: 0.0893\n",
      "Epoch 90/100, Loss: 0.0793\n",
      "Epoch 100/100, Loss: 0.0713\n",
      "Fold 4 Accuracy: 0.92\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 10/100, Loss: 0.4402\n",
      "Epoch 20/100, Loss: 0.2859\n",
      "Epoch 30/100, Loss: 0.2193\n",
      "Epoch 40/100, Loss: 0.1777\n",
      "Epoch 50/100, Loss: 0.1517\n",
      "Epoch 60/100, Loss: 0.1330\n",
      "Epoch 70/100, Loss: 0.1179\n",
      "Epoch 80/100, Loss: 0.1061\n",
      "Epoch 90/100, Loss: 0.0950\n",
      "Epoch 100/100, Loss: 0.0863\n",
      "Fold 5 Accuracy: 0.92\n",
      "\n",
      "Average accuracy across 5 folds: 0.93\n",
      "Test Accuracy: 95.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = train(X_train, y_train)\n",
    "\n",
    "    batch_size = 32\n",
    "    X_torch = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_torch = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "    dataset = TensorDataset(X_torch, y_torch)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    accuracy = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total, correct = 0, 0\n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            logits  = model(x_batch)\n",
    "            preds   = (logits >= 0.5).long()\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        accuracy.append(acc)\n",
    "\n",
    "    print(f\"Test Accuracy: {np.mean(accuracy)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa65c9-0eb4-46db-9c20-57a3f7119f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
